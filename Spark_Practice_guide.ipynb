{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KQIUss6ueM1Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFFZzSHmMRpU",
        "outputId": "c3265007-1b74-4144-c546-c522a0831a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=95248afc80b2be72147d65e081b3c7990f5a0bce55bac5a71ee79efeb80c4b2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark import SparkContext\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### for older versions of Spark we use SparkContext to interact with Spark but the for >2.0 versions SparkSession is used to instead of SparkContext."
      ],
      "metadata": {
        "id": "Gw0KRdk5Up-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## creating SparkContext with 2 CPU cores\n",
        "sc=SparkContext(master=\"local[2]\")"
      ],
      "metadata": {
        "id": "l5ujdZn0MU2t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst=np.random.randint(0,10,20)\n",
        "print(lst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SElR_6FYMU5f",
        "outputId": "82f1ee2c-e7dc-46ce-aef2-f368ac6ee681"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 8 7 5 7 8 7 8 6 8 1 5 0 5 6 0 1 6 4 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_rdd=sc.parallelize(lst)\n",
        "my_rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gm6VajLMU74",
        "outputId": "04e001bd-b07a-4d42-f239-3d2347e92606"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 8, 7, 5, 7, 8, 7, 8, 6, 8, 1, 5, 0, 5, 6, 0, 1, 6, 4, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## using glom to view how the data in RDD is spread across the 2 paritions in different Nodes\n",
        "my_rdd.glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMPr--1pMU-O",
        "outputId": "488b5ae5-2f4e-45fd-b47d-2847eebf9bdc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 8, 7, 5, 7, 8, 7, 8, 6, 8], [1, 5, 0, 5, 6, 0, 1, 6, 4, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "ROewEaXvMVBW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spread across the 3 paritions in different Nodes\n",
        "sc2=SparkContext(master=\"local[3]\")\n",
        "my_rdd2=sc2.parallelize(lst)\n",
        "my_rdd2.glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk7MQXFuMVEF",
        "outputId": "c5e630c9-1e45-4cda-de99-0bfc654913e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 8, 7, 5, 7, 8], [7, 8, 6, 8, 1, 5], [0, 5, 6, 0, 1, 6, 4, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_rdd2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFjnEc-HMVG2",
        "outputId": "4e529a9f-f10d-4065-d56f-437992f7ca83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_distinct=my_rdd2.distinct()\n",
        "rdd_distinct.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUbqmIpCMVKP",
        "outputId": "f58162c7-8c88-4feb-b810-177b8b45257d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 0, 7, 1, 4, 8, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## using Reduce method to get overall aggregated values"
      ],
      "metadata": {
        "id": "dw_NgYqwXQHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_distinct.reduce(lambda a,b:a+b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKsAcU6FMVNx",
        "outputId": "4575a89c-0cf9-4bab-8115-58552f05e9e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_distinct.reduce(lambda a,b:a if a>b else b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI0nvonVXjMZ",
        "outputId": "7af7b5ca-3261-4b2b-ff7a-277f8e9a468a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = 'These always exists a unknow thing in science to find and explore it is a continous learing process'.split(' ')\n",
        "w_rdd=sc2.parallelize(words)\n",
        "w_rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GrJ5udSXjPZ",
        "outputId": "67961dc3-fecc-4dbc-8478-2a8d61942b08"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['These',\n",
              " 'always',\n",
              " 'exists',\n",
              " 'a',\n",
              " 'unknow',\n",
              " 'thing',\n",
              " 'in',\n",
              " 'science',\n",
              " 'to',\n",
              " 'find',\n",
              " 'and',\n",
              " 'explore',\n",
              " 'it',\n",
              " 'is',\n",
              " 'a',\n",
              " 'continous',\n",
              " 'learing',\n",
              " 'process']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## map applies a function on each element and return new RDD with similar collections\n",
        "a=rdd_distinct.map(lambda x:(x,x*x))\n",
        "a.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHIGxed1XjS5",
        "outputId": "ee0389a6-1427-4db9-c8c0-90025ab018fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(6, 36), (0, 0), (7, 49), (1, 1), (4, 16), (8, 64), (5, 25)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## applies on each element but returns the entire group in form of single rdd without any collections\n",
        "rdd_distinct.flatMap(lambda x:(x,x*x)).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiVKIuOuZ5Vc",
        "outputId": "f7f30b2f-6b42-425b-c443-cd7362209378"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 36, 0, 0, 7, 49, 1, 1, 4, 16, 8, 64, 5, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=w_rdd.groupBy(lambda x:len(x)).collect()\n",
        "print(sorted([(key,sorted(val)) for key,val in c]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AivZshWgaf9k",
        "outputId": "e9a4f98a-2762-433e-98e5-073a14701593"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, ['a', 'a']), (2, ['in', 'is', 'it', 'to']), (3, ['and']), (4, ['find']), (5, ['These', 'thing']), (6, ['always', 'exists', 'unknow']), (7, ['explore', 'learing', 'process', 'science']), (9, ['continous'])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc2.stop()"
      ],
      "metadata": {
        "id": "B23WOkjFcIrn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now using the Spark Session to explore DataFrame"
      ],
      "metadata": {
        "id": "BCr7qewXcIFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Spark DataFrame basics"
      ],
      "metadata": {
        "id": "5A55-ZuOekUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark=SparkSession.builder.appName('Data Frame intro').getOrCreate()\n",
        "df0 = spark.read.format('json').options(inferSchema=True,Header=True).load('/content/sample_data/anscombe.json')\n"
      ],
      "metadata": {
        "id": "x9Tp8bgSb1r4"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding user_defined Schema similar to SQL works only with Databricks\n",
        "\n",
        "#### uds='Series_rank STRING, X DECIMAL(10,2), Y DECIMAL(10,2)'\n",
        "\n",
        "#### df0 = spark.read.format('json').options(inferSchema=False,).schema(uds).load('/content/sample_data/anscombe.json')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S-w0naFxi01-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df0.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXacWMXfb1ug",
        "outputId": "591d349f-b0e3-4cfd-c8d1-f883afebfad7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Series: string (nullable = true)\n",
            " |-- X: double (nullable = true)\n",
            " |-- Y: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df0.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJcLUjHsenK1",
        "outputId": "739fa61f-3afd-4db3-b958-6ea2dc901ba4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----+\n",
            "|Series|   X|    Y|\n",
            "+------+----+-----+\n",
            "|     I|10.0| 8.04|\n",
            "|     I| 8.0| 6.95|\n",
            "|     I|13.0| 7.58|\n",
            "|     I| 9.0| 8.81|\n",
            "|     I|11.0| 8.33|\n",
            "|     I|14.0| 9.96|\n",
            "|     I| 6.0| 7.24|\n",
            "|     I| 4.0| 4.26|\n",
            "|     I|12.0|10.84|\n",
            "|     I| 7.0| 4.81|\n",
            "|     I| 5.0| 5.68|\n",
            "|    II|10.0| 9.14|\n",
            "|    II| 8.0| 8.14|\n",
            "|    II|13.0| 8.74|\n",
            "|    II| 9.0| 8.77|\n",
            "|    II|11.0| 9.26|\n",
            "|    II|14.0|  8.1|\n",
            "|    II| 6.0| 6.13|\n",
            "|    II| 4.0|  3.1|\n",
            "|    II|12.0| 9.13|\n",
            "+------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StringType, IntegerType, StructField\n",
        "new_schema=StructType([StructField(\"name\",StringType(),True),StructField(\"age\",IntegerType(),False)])\n",
        "print(new_schema)\n",
        "df0.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c13xAjXV-dJ0",
        "outputId": "ee875bae-3756-4a8e-f106-6ac08420ffb6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StructType([StructField('name', StringType(), True), StructField('age', IntegerType(), False)])\n",
            "+------+----+-----+\n",
            "|Series|   X|    Y|\n",
            "+------+----+-----+\n",
            "|     I|10.0| 8.04|\n",
            "|     I| 8.0| 6.95|\n",
            "|     I|13.0| 7.58|\n",
            "|     I| 9.0| 8.81|\n",
            "|     I|11.0| 8.33|\n",
            "|     I|14.0| 9.96|\n",
            "|     I| 6.0| 7.24|\n",
            "|     I| 4.0| 4.26|\n",
            "|     I|12.0|10.84|\n",
            "|     I| 7.0| 4.81|\n",
            "|     I| 5.0| 5.68|\n",
            "|    II|10.0| 9.14|\n",
            "|    II| 8.0| 8.14|\n",
            "|    II|13.0| 8.74|\n",
            "|    II| 9.0| 8.77|\n",
            "|    II|11.0| 9.26|\n",
            "|    II|14.0|  8.1|\n",
            "|    II| 6.0| 6.13|\n",
            "|    II| 4.0|  3.1|\n",
            "|    II|12.0| 9.13|\n",
            "+------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.format('csv').options(inferSchema=True,header=True).load('/content/sample_data/california_housing_train.csv')\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Irss7_KW8nfW",
        "outputId": "e51f88be-6748-461a-87d5-b1696555fa7a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common format used to read data from different files\n",
        "\n",
        "\n",
        "df= spark.read.format('filetype').options(inferSchema=True/False,sep=',',header=True/False).schema(user_defined_schema).load('<file path/ can be a folder also that has multiple files >')\n",
        "\n",
        "Valid options for filetype:\n",
        "\n",
        "'csv' , 'avro', 'json', 'parquet', 'orc'\n",
        "\n",
        "Valid options:\n",
        " inferSchema=True/False\n",
        "\n",
        " header=True/False\n",
        " \n",
        " sep=\"< delimiter char >\"\n",
        "\n",
        "Incase of inferSchema set to False and user wants to provide explict schema use the schema option:\n",
        "\n",
        "user_defined_schema= \n",
        "schema(user_defined_schema)\n",
        "\n",
        "2 ways to define schema\n",
        "\n",
        "using StructType()\n",
        "\n",
        "\n",
        "Using SQL like schema: **(valid only for databricks)**\n",
        "\n",
        "user_defined_schema='column_name DATATYPE, Col2 DATATYPE...'"
      ],
      "metadata": {
        "id": "oGBaRdN48_S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYNUNd89b1xk",
        "outputId": "93acc692-6ee4-4bf9-865e-54e34907b0ee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZYLx4X5BSpx",
        "outputId": "dd41fd01-8113-4d48-e481-f43922a906ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## REading data from multiple files to single dataframe\n",
        "df2=spark.read.format('csv').options(inferSchema=True,header=True).load(['/content/sample_data/california_housing_train.csv',\n",
        "                                                             '/content/sample_data/california_housing_test.csv'])\n",
        "df2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPSJVhOwb11G",
        "outputId": "aca031aa-5fc0-4055-dffe-b3bcfe3231ce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYhhZ1X8BiCL",
        "outputId": "243d4141-f2f2-464b-845a-a03b1842db30"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df['longitude'])\n",
        "## columns are of sql.column type "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuuTJIUtJSTW",
        "outputId": "eaaa40c1-52f7-4e31-c6bb-f8efe28e11d1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.column.Column"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df.head(2)[0])\n",
        "## rows are of sql.row type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmLQtJ97JSZW",
        "outputId": "f27fd7eb-f932-4ddd-d6aa-18c88f51ae6a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.types.Row"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting each column values can be shown by using\n",
        "\n",
        "##### df.select('col1') \n",
        "\n"
      ],
      "metadata": {
        "id": "IzVWwr4UJxE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('longitude').show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UegM_rADJtDx",
        "outputId": "184b8df7-7043-4ee5-9b8c-021d63023bf8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|longitude|\n",
            "+---------+\n",
            "|  -114.31|\n",
            "|  -114.47|\n",
            "|  -114.56|\n",
            "|  -114.57|\n",
            "|  -114.57|\n",
            "+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(['longitude','latitude']).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVKtEwGCJtMH",
        "outputId": "1e864f7a-4a42-4c6b-c5ae-aedac2ae64f8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+\n",
            "|longitude|latitude|\n",
            "+---------+--------+\n",
            "|  -114.31|   34.19|\n",
            "|  -114.47|    34.4|\n",
            "|  -114.56|   33.69|\n",
            "|  -114.57|   33.64|\n",
            "|  -114.57|   33.57|\n",
            "|  -114.58|   33.63|\n",
            "|  -114.58|   33.61|\n",
            "|  -114.59|   34.83|\n",
            "|  -114.59|   33.61|\n",
            "|   -114.6|   34.83|\n",
            "+---------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## asDict() method allows to get the spark rows in dictionary form\n",
        "\n",
        "df.head(2)[0].asDict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFxy11VFJScD",
        "outputId": "dada3f97-ba72-4358-c981-e94b2003cd1b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'longitude': -114.31,\n",
              " 'latitude': 34.19,\n",
              " 'housing_median_age': 15.0,\n",
              " 'total_rooms': 5612.0,\n",
              " 'total_bedrooms': 1283.0,\n",
              " 'population': 1015.0,\n",
              " 'households': 472.0,\n",
              " 'median_income': 1.4936,\n",
              " 'median_house_value': 66900.0}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### withColumn('column name', value) used to create new column in data or mainpulate \n",
        "\n",
        "its values \n",
        "### columns can be renamed using withColumnRenamed('old',  'new')\n",
        "\n",
        "### drop column with df.drop('column name')"
      ],
      "metadata": {
        "id": "BgHyZK1IOPww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn('room_per_person',df['total_rooms']/df['population']).limit(5).select(['room_per_person','total_rooms','population']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yme73m-yJSfl",
        "outputId": "0b8d4b39-1879-4360-bcc0-7c5bccfe4c88"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----------+----------+\n",
            "|   room_per_person|total_rooms|population|\n",
            "+------------------+-----------+----------+\n",
            "| 5.529064039408867|     5612.0|    1015.0|\n",
            "| 6.775907883082374|     7650.0|    1129.0|\n",
            "|2.1621621621621623|      720.0|     333.0|\n",
            "|2.9145631067961166|     1501.0|     515.0|\n",
            "|2.3301282051282053|     1454.0|     624.0|\n",
            "+------------------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter('total_rooms>1000  and median_house_value<60000').show()"
      ],
      "metadata": {
        "id": "rUvJor6jL9--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f311e9-431d-4ee0-ab05-c2388f2a08ed"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.68|   33.49|              20.0|     1491.0|         360.0|    1135.0|     303.0|       1.6395|           44400.0|\n",
            "|  -115.22|   33.54|              18.0|     1706.0|         397.0|    3424.0|     283.0|        1.625|           53500.0|\n",
            "|  -115.46|   33.19|              33.0|     1234.0|         373.0|     777.0|     298.0|          1.0|           40000.0|\n",
            "|  -115.51|   33.24|              32.0|     1995.0|         523.0|    1069.0|     410.0|       1.6552|           43300.0|\n",
            "|  -115.51|   33.12|              21.0|     1024.0|         218.0|     890.0|     232.0|        2.101|           46700.0|\n",
            "|  -115.52|   33.13|              18.0|     1109.0|         283.0|    1006.0|     253.0|        2.163|           53400.0|\n",
            "|  -115.52|   32.98|              32.0|     1615.0|         382.0|    1307.0|     345.0|       1.4583|           58600.0|\n",
            "|  -115.55|   32.79|              23.0|     1004.0|         221.0|     697.0|     201.0|       1.6351|           59600.0|\n",
            "|  -115.56|    32.8|              28.0|     1672.0|         416.0|    1335.0|     397.0|       1.5987|           59400.0|\n",
            "|  -115.56|   32.79|              18.0|     1178.0|         438.0|    1377.0|     429.0|       1.3373|           58300.0|\n",
            "|  -115.69|   32.79|              18.0|     1564.0|         340.0|    1161.0|     343.0|       2.1792|           55200.0|\n",
            "|  -115.73|   33.35|              23.0|     1586.0|         448.0|     338.0|     182.0|       1.2132|           30000.0|\n",
            "|  -115.85|    34.2|              34.0|     3868.0|        1257.0|     890.0|     423.0|       1.3571|           41000.0|\n",
            "|  -115.99|    33.4|              15.0|     1945.0|         536.0|     515.0|     273.0|       2.0109|           54300.0|\n",
            "|   -116.0|   32.74|              26.0|     1134.0|         280.0|     329.0|     158.0|       1.4338|           43900.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter((df.total_rooms>6000) & (df.median_house_value<60000)).show(5)"
      ],
      "metadata": {
        "id": "AxcgMEIQL-Bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561cefa2-0dbf-4912-e244-387d928d3c9a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -116.51|   34.45|              21.0|     8502.0|        2634.0|    2330.0|     991.0|       1.3811|           51300.0|\n",
            "|  -116.57|   35.43|               8.0|     9975.0|        1743.0|    6835.0|    1439.0|       2.7138|           22500.0|\n",
            "|  -117.29|   35.54|              35.0|     7922.0|        1636.0|    3431.0|    1329.0|       3.4145|           40400.0|\n",
            "|  -117.37|   34.59|              39.0|     8193.0|        1747.0|    6852.0|    1597.0|       2.3832|           35000.0|\n",
            "|   -118.9|   35.26|              31.0|     6145.0|        1492.0|    5666.0|    1457.0|       1.9066|           54600.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### other commands for filter inclue\n",
        "\n",
        "df.column.isNull()\n",
        "\n",
        "df.column.isNotNull()\n",
        "\n",
        "df.column.isin((a,b,c)\n",
        "\n",
        "~df.column.isin(a,b,c...)\n",
        "\n",
        "df.column.like('%cecemkmlce%)\n",
        "\n",
        "df.column.contains('cddec')\n",
        "\n",
        "df.column.startswith('a')\n",
        "\n",
        "df.column.endswith('i)\n",
        "\n"
      ],
      "metadata": {
        "id": "bT_FymzoSnpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d=[('Robert',23),('Alen',24),('Jason',20),('Peter',22),('June',22),('Alex',25),('Leo',24)]\n",
        "\n",
        "df2=spark.createDataFrame(d,schema=['name','age'])\n",
        "\n",
        "df2.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgb0QZKsrmR5",
        "outputId": "72e55a3d-ecfd-4ddd-9bd3-f5399fe15c85"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|  name|age|\n",
            "+------+---+\n",
            "|Robert| 23|\n",
            "|  Alen| 24|\n",
            "| Jason| 20|\n",
            "| Peter| 22|\n",
            "|  June| 22|\n",
            "|  Alex| 25|\n",
            "|   Leo| 24|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtSO-ZnMrmUx",
        "outputId": "44e83c92-75a0-43cc-f9d1-811db11a061e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.filter(df2.name.like('%n%')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f1xyy9ZrmYP",
        "outputId": "d420dc43-f0f2-40f2-d182-d11729694c5e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "| Alen| 24|\n",
            "|Jason| 20|\n",
            "| June| 22|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.filter(df2.name.contains('e')).show()"
      ],
      "metadata": {
        "id": "fiKd13i2L-E8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca6db66-b304-4b3d-c80b-61cfc09eb45f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|  name|age|\n",
            "+------+---+\n",
            "|Robert| 23|\n",
            "|  Alen| 24|\n",
            "| Peter| 22|\n",
            "|  June| 22|\n",
            "|  Alex| 25|\n",
            "|   Leo| 24|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.filter(df2.name.startswith('A')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjftz2GuVj3c",
        "outputId": "c10a0b8d-13ea-4b13-9bb7-4b7f79d4a906"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+\n",
            "|name|age|\n",
            "+----+---+\n",
            "|Alen| 24|\n",
            "|Alex| 25|\n",
            "+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.filter(df2.age.isin(22,24)).select(['name','age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JhJ7Ni9VmCT",
        "outputId": "585b461a-ca27-4476-f6b0-98b58927da98"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "| Alen| 24|\n",
            "|Peter| 22|\n",
            "| June| 22|\n",
            "|  Leo| 24|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In order to create single column data frame specify the schema of each row then use to toDF('abc') to return the data as dataframe with mentioned column name.  Or use rename column \n"
      ],
      "metadata": {
        "id": "P1NJg1m7X--o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3=spark.createDataFrame(['SL','IN','US','GM','JP','GM','JP'],schema='string').toDF('country')\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6evdwEIXVmFd",
        "outputId": "70154f3d-4a29-4181-e32d-081e65f6139c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|country|\n",
            "+-------+\n",
            "|     SL|\n",
            "|     IN|\n",
            "|     US|\n",
            "|     GM|\n",
            "|     JP|\n",
            "|     GM|\n",
            "|     JP|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4=spark.createDataFrame(['SL','IN','US','GM','JP','GM','JP'],schema='string')\n",
        "df4.printSchema()\n",
        "df4=df4.withColumnRenamed('value','country')\n",
        "df4.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_ACcDRRYdZS",
        "outputId": "b0d40fff-0114-4574-9404-ed0f3f42d100"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- country: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit, concat\n",
        "\n",
        "## lit is a function used to convert any object passed to it into a Column datatype in\n",
        "\n",
        "## concat is used to concat 2 or more columns together into 1 single column\n",
        "\n",
        "df6=df2.withColumn('college mail',concat(lit('student_'),df2.name,lit('22_@xav.com')))\n",
        "df6.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNFR0hRyVmIh",
        "outputId": "674bfbd5-3c2e-4a45-86d1-281f16f2cb6b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+--------------------+\n",
            "|  name|age|        college mail|\n",
            "+------+---+--------------------+\n",
            "|Robert| 23|student_Robert22_...|\n",
            "|  Alen| 24|student_Alen22_@x...|\n",
            "| Jason| 20|student_Jason22_@...|\n",
            "| Peter| 22|student_Peter22_@...|\n",
            "|  June| 22|student_June22_@x...|\n",
            "|  Alex| 25|student_Alex22_@x...|\n",
            "|   Leo| 24|student_Leo22_@xa...|\n",
            "+------+---+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import substring\n",
        "df7=df6.withColumn('nick',substring(df6.name,2,4))\n",
        "df7.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ397VPDVmMA",
        "outputId": "3a00a095-9851-4eb4-b997-58de9244adae"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+--------------------+----+\n",
            "|  name|age|        college mail|nick|\n",
            "+------+---+--------------------+----+\n",
            "|Robert| 23|student_Robert22_...|ober|\n",
            "|  Alen| 24|student_Alen22_@x...| len|\n",
            "| Jason| 20|student_Jason22_@...|ason|\n",
            "| Peter| 22|student_Peter22_@...|eter|\n",
            "|  June| 22|student_June22_@x...| une|\n",
            "|  Alex| 25|student_Alex22_@x...| lex|\n",
            "|   Leo| 24|student_Leo22_@xa...|  eo|\n",
            "+------+---+--------------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import column\n",
        "df3.withColumn('test',df3.country.endswith('N')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9gUu_hlcleG",
        "outputId": "731a7ee6-2139-42a6-b1c0-508c20f11e23"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|country| test|\n",
            "+-------+-----+\n",
            "|     SL|false|\n",
            "|     IN| true|\n",
            "|     US|false|\n",
            "|     GM|false|\n",
            "|     JP|false|\n",
            "|     GM|false|\n",
            "|     JP|false|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### drop is used to remove the column inplace \n",
        "\n",
        "df.drop('col name')\n",
        "can used to drop only 1 column at once\n",
        "\n",
        "df.drop('col1').drop('col2') can be used to used multiple columns at once."
      ],
      "metadata": {
        "id": "FYTeO2lko-H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3.drop('test')\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlJI2G-zclhu",
        "outputId": "df70e235-9235-450e-9c86-755d4aa7ab89"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|country|\n",
            "+-------+\n",
            "|     SL|\n",
            "|     IN|\n",
            "|     US|\n",
            "|     GM|\n",
            "|     JP|\n",
            "|     GM|\n",
            "|     JP|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.sort('country').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSvs_AdFVj6H",
        "outputId": "c95baad6-6305-4fb6-f763-74020a560c5b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|country|\n",
            "+-------+\n",
            "|     GM|\n",
            "|     GM|\n",
            "|     IN|\n",
            "|     JP|\n",
            "|     JP|\n",
            "|     SL|\n",
            "|     US|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.sort(\"country\",ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4ogg6UlVj9_",
        "outputId": "a67a2b9c-22ce-453c-958a-bbc309d75896"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|country|\n",
            "+-------+\n",
            "|     US|\n",
            "|     SL|\n",
            "|     JP|\n",
            "|     JP|\n",
            "|     IN|\n",
            "|     GM|\n",
            "|     GM|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Orders the data based on list of columns mentioned in order\n",
        "\n",
        "#### agg is used to perform any aggregation over group of values in dataframe"
      ],
      "metadata": {
        "id": "0NLQk_KpYkfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.orderBy(['name','age'],ascending=[0,1]).show()\n",
        "## ascending takes a list of value interpreted as True  or False applied to sort based on each column values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXFUNbveXr3k",
        "outputId": "0dd8a776-4d4a-4972-c042-9411a1fb992b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|  name|age|\n",
            "+------+---+\n",
            "|Robert| 23|\n",
            "| Peter| 22|\n",
            "|   Leo| 24|\n",
            "|  June| 22|\n",
            "| Jason| 20|\n",
            "|  Alex| 25|\n",
            "|  Alen| 24|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## corr --> gives correlation between 2 mentioned columns  \n",
        "from pyspark.sql.functions import corr, dayofweek, dayofmonth, month, year \n",
        "\n",
        "df.agg(corr(df.median_house_value,df.total_rooms).alias('rooms_value_corr')).select('rooms_value_corr').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZGyZJuhXr6j",
        "outputId": "51e3fd5d-5530-49d4-e568-ff2405a6f0d9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|   rooms_value_corr|\n",
            "+-------------------+\n",
            "|0.13099146625326655|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GroupBy, agg (aggregrate), 'orderBy' operations\n"
      ],
      "metadata": {
        "id": "bxr-2TeZoJq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df0.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEqo_xkIeXGJ",
        "outputId": "f825e6d8-4f36-4af2-9624-40b6bd3debbb"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----+\n",
            "|Series|   X|    Y|\n",
            "+------+----+-----+\n",
            "|     I|10.0| 8.04|\n",
            "|     I| 8.0| 6.95|\n",
            "|     I|13.0| 7.58|\n",
            "|     I| 9.0| 8.81|\n",
            "|     I|11.0| 8.33|\n",
            "|     I|14.0| 9.96|\n",
            "|     I| 6.0| 7.24|\n",
            "|     I| 4.0| 4.26|\n",
            "|     I|12.0|10.84|\n",
            "|     I| 7.0| 4.81|\n",
            "|     I| 5.0| 5.68|\n",
            "|    II|10.0| 9.14|\n",
            "|    II| 8.0| 8.14|\n",
            "|    II|13.0| 8.74|\n",
            "|    II| 9.0| 8.77|\n",
            "|    II|11.0| 9.26|\n",
            "|    II|14.0|  8.1|\n",
            "|    II| 6.0| 6.13|\n",
            "|    II| 4.0|  3.1|\n",
            "|    II|12.0| 9.13|\n",
            "+------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df10=df0.select('X','Y','Series').groupBy('Series').mean().select('avg(X)','avg(Y)','Series')\n",
        "df10.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQVBubmjbu_c",
        "outputId": "43379be5-b1f7-4f12-994d-17e6272aa918"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------+------+\n",
            "|avg(X)|           avg(Y)|Series|\n",
            "+------+-----------------+------+\n",
            "|   9.0|7.500000000000001|   III|\n",
            "|   9.0| 7.50090909090909|    IV|\n",
            "|   9.0|7.500909090909091|    II|\n",
            "|   9.0|              7.5|     I|\n",
            "+------+-----------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df11=df0.select('X','Y','Series').groupBy('Series').max().select('max(X)','max(Y)','Series')\n",
        "df11.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ssdw8VEdaAX",
        "outputId": "89c5da45-a17a-4893-cbfd-723b02164685"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+------+\n",
            "|max(X)|max(Y)|Series|\n",
            "+------+------+------+\n",
            "|  14.0| 12.74|   III|\n",
            "|  19.0|  12.5|    IV|\n",
            "|  14.0|  9.26|    II|\n",
            "|  14.0| 10.84|     I|\n",
            "+------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df11=df0.select('X','Y','Series').groupBy('Series').min().select('min(X)','min(Y)','Series')\n",
        "df11.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i92avlIdZ8-",
        "outputId": "2bdd0b34-df80-4fe6-b293-cd8f9c140776"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+------+\n",
            "|min(X)|min(Y)|Series|\n",
            "+------+------+------+\n",
            "|   4.0|  5.39|   III|\n",
            "|   8.0|  5.25|    IV|\n",
            "|   4.0|   3.1|    II|\n",
            "|   4.0|  4.26|     I|\n",
            "+------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## No of non null valued rows\n",
        "df11=df0.select('X','Y','Series').groupBy('Series').count().select('count','Series')\n",
        "df11.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5zPrVGDbvC0",
        "outputId": "8a4b1292-037f-4628-fbf1-bc558bab8902"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "|count|Series|\n",
            "+-----+------+\n",
            "|   11|   III|\n",
            "|   11|    IV|\n",
            "|   11|    II|\n",
            "|   11|     I|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df0.groupBy('Series').count().show()"
      ],
      "metadata": {
        "id": "_nURn8BKvWkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5fc920e-2b8b-405d-a552-a4df19fdc361"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Series|count|\n",
            "+------+-----+\n",
            "|   III|   11|\n",
            "|    IV|   11|\n",
            "|    II|   11|\n",
            "|     I|   11|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df0.groupBy('Series').count().collect()\n"
      ],
      "metadata": {
        "id": "QXzeT8_SvWm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c38302-c858-41dd-d5cc-ff288e55b201"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Series='III', count=11),\n",
              " Row(Series='IV', count=11),\n",
              " Row(Series='II', count=11),\n",
              " Row(Series='I', count=11)]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### aggregations syntax\n",
        "\n",
        "df.agg({'column_name':'aggregation_operation','col2':'stddev',....})"
      ],
      "metadata": {
        "id": "4geU6nRdpIBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## General convention create a dataframe with groupby and use the same data to apply multiple aggregations\n",
        "from pyspark.sql.functions import round, countDistinct\n",
        "\n",
        "group_data=df0.groupBy('Series')\n",
        "d0=group_data.agg({'X':'mean','Y':'stddev'})\n",
        "d0.select('Series', *[round(i,2) for i in d0.columns[1:]] ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDFM0f51opvb",
        "outputId": "9c1ea9ae-3108-493d-cd66-f80a1cc3920d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------+-------------------+\n",
            "|Series|round(avg(X), 2)|round(stddev(Y), 2)|\n",
            "+------+----------------+-------------------+\n",
            "|   III|             9.0|               2.03|\n",
            "|    IV|             9.0|               2.03|\n",
            "|    II|             9.0|               2.03|\n",
            "|     I|             9.0|               2.03|\n",
            "+------+----------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}